Hide navigation sidebarHide table of contents sidebar
Boto3 1.35.77 documentation
Toggle Light / Dark / Auto color theme
Toggle site navigation sidebar
Light Logo
Boto3 1.35.77 documentation
Search
Feedback

Do you have a suggestion to improve this website or boto3? Give us feedback.

Quickstart
A Sample Tutorial
Code Examples
Developer Guide
Security
Available Services
AccessAnalyzer
Account
ACM
ACMPCA
PrometheusService
Amplify
AmplifyBackend
AmplifyUIBuilder
APIGateway
ApiGatewayManagementApi
ApiGatewayV2
AppConfig
AppConfigData
AppFabric
Appflow
AppIntegrationsService
ApplicationAutoScaling
ApplicationInsights
CloudWatchApplicationSignals
ApplicationCostProfiler
AppMesh
AppRunner
AppStream
AppSync
MainframeModernizationApplicationTesting
ARCZonalShift
Artifact
Athena
AuditManager
AutoScaling
AutoScalingPlans
B2BI
Backup
BackupGateway
Batch
BillingandCostManagementDataExports
BillingandCostManagementPricingCalculator
Bedrock
AgentsforBedrock
AgentsforBedrockRuntime
DataAutomationforBedrock
RuntimeforBedrockDataAutomation
BedrockRuntime
Billing
BillingConductor
Braket
Budgets
CostExplorer
Chatbot
Chime
ChimeSDKIdentity
ChimeSDKMediaPipelines
ChimeSDKMeetings
ChimeSDKMessaging
ChimeSDKVoice
CleanRoomsService
CleanRoomsML
Cloud9
CloudControlApi
CloudDirectory
CloudFormation
CloudFront
CloudFrontKeyValueStore
CloudHSM
CloudHSMV2
CloudSearch
CloudSearchDomain
CloudTrail
CloudTrailDataService
CloudWatch
CodeArtifact
CodeBuild
CodeCatalyst
CodeCommit
CodeConnections
CodeDeploy
CodeGuruReviewer
CodeGuruSecurity
CodeGuruProfiler
CodePipeline
CodeStarconnections
CodeStarNotifications
CognitoIdentity
CognitoIdentityProvider
CognitoSync
Comprehend
ComprehendMedical
ComputeOptimizer
ConfigService
Connect
ConnectContactLens
ConnectCampaignService
ConnectCampaignServiceV2
ConnectCases
ConnectParticipant
ControlCatalog
ControlTower
CostOptimizationHub
CostandUsageReportService
CustomerProfiles
GlueDataBrew
DataExchange
DataPipeline
DataSync
DataZone
DAX
DeadlineCloud
Detective
DeviceFarm
DevOpsGuru
DirectConnect
ApplicationDiscoveryService
DLM
DatabaseMigrationService
DocDB
DocDBElastic
drs
DirectoryService
DirectoryServiceData
AuroraDSQL
DynamoDB
DynamoDBStreams
EBS
EC2
EC2InstanceConnect
ECR
ECRPublic
ECS
EFS
EKS
EKSAuth
ElasticInference
ElastiCache
ElasticBeanstalk
ElasticTranscoder
ElasticLoadBalancing
ElasticLoadBalancingv2
EMR
EMRContainers
EMRServerless
EntityResolution
ElasticsearchService
EventBridge
CloudWatchEvidently
finspace
FinSpaceData
Firehose
FIS
FMS
ForecastService
ForecastQueryService
FraudDetector
FreeTier
FSx
GameLift
LocationServiceMapsV2
LocationServicePlacesV2
LocationServiceRoutesV2
Glacier
GlobalAccelerator
Glue
ManagedGrafana
Greengrass
GreengrassV2
GroundStation
GuardDuty
Health
HealthLake
IAM
IdentityStore
imagebuilder
ImportExport
Inspector
inspectorscan
Inspector2
CloudWatchInternetMonitor
Invoicing
IoT
IoTDataPlane
IoTJobsDataPlane
IoT1ClickDevicesService
IoT1ClickProjects
IoTAnalytics
IoTDeviceAdvisor
IoTEvents
IoTEventsData
IoTFleetHub
IoTFleetWise
IoTSecureTunneling
IoTSiteWise
IoTThingsGraph
IoTTwinMaker
IoTWireless
IVS
ivsrealtime
ivschat
Kafka
KafkaConnect
kendra
KendraRanking
Keyspaces
Kinesis
KinesisVideoArchivedMedia
KinesisVideoMedia
KinesisVideoSignalingChannels
KinesisVideoWebRTCStorage
KinesisAnalytics
KinesisAnalyticsV2
KinesisVideo
KMS
LakeFormation
Lambda
LaunchWizard
LexModelBuildingService
LexRuntimeService
LexModelsV2
LexRuntimeV2
LicenseManager
LicenseManagerLinuxSubscriptions
LicenseManagerUserSubscriptions
Lightsail
LocationService
CloudWatchLogs
LookoutEquipment
LookoutMetrics
LookoutforVision
MainframeModernization
MachineLearning
Macie2
MailManager
ManagedBlockchain
ManagedBlockchainQuery
AgreementService
MarketplaceCatalog
MarketplaceDeploymentService
MarketplaceEntitlementService
MarketplaceReportingService
MarketplaceCommerceAnalytics
MediaConnect
MediaConvert
MediaLive
MediaPackage
MediaPackageVod
mediapackagev2
MediaStore
MediaStoreData
MediaTailor
HealthImaging
MemoryDB
MarketplaceMetering
MigrationHub
mgn
MigrationHubRefactorSpaces
MigrationHubConfig
MigrationHubOrchestrator
MigrationHubStrategyRecommendations
MQ
MTurk
MWAA
Neptune
NeptuneGraph
NeptuneData
NetworkFirewall
NetworkFlowMonitor
NetworkManager
CloudWatchNetworkMonitor
UserNotifications
UserNotificationsContacts
CloudWatchObservabilityAccessManager
CloudWatchObservabilityAdminService
Omics
OpenSearchService
OpenSearchServiceServerless
OpsWorks
OpsWorksCM
Organizations
OpenSearchIngestion
Outposts
Panorama
PartnerCentralSellingAPI
PaymentCryptographyControlPlane
PaymentCryptographyDataPlane
PcaConnectorAd
PrivateCAConnectorforSCEP
ParallelComputingService
Personalize
PersonalizeEvents
PersonalizeRuntime
PI
Pinpoint
PinpointEmail
PinpointSMSVoice
PinpointSMSVoiceV2
EventBridgePipes
Polly
Pricing
Private5G
Proton
QApps
QBusiness
QConnect
QLDB
QLDBSession
QuickSight
RAM
RecycleBin
RDS
RDSDataService
Redshift
RedshiftDataAPIService
RedshiftServerless
Rekognition
rePostPrivate
ResilienceHub
ResourceExplorer
ResourceGroups
ResourceGroupsTaggingAPI
RoboMaker
IAMRolesAnywhere
Route53
Route53RecoveryCluster
Route53RecoveryControlConfig
Route53RecoveryReadiness
Route53Domains
Route53Profiles
Route53Resolver
CloudWatchRUM
S3
S3Control
S3Outposts
S3Tables
SageMaker
AugmentedAIRuntime
SagemakerEdgeManager
SageMakerFeatureStoreRuntime
SageMakergeospatialcapabilities
SageMakerMetrics
SageMakerRuntime
SavingsPlans
EventBridgeScheduler
Schemas
SimpleDB
SecretsManager
SecurityIncidentResponse
SecurityHub
SecurityLake
ServerlessApplicationRepository
ServiceQuotas
ServiceCatalog
AppRegistry
ServiceDiscovery
SES
SESV2
Shield
signer
SimSpaceWeaver
SMS
SnowDeviceManagement
Snowball
SNS
EndUserMessagingSocial
SQS
SSM
SSMContacts
SSMIncidents
SystemsManagerQuickSetup
SsmSap
SSO
SSOAdmin
SSOOIDC
SFN
StorageGateway
STS
SupplyChain
Support
SupportApp
SWF
Synthetics
TaxSettings
Textract
TimestreamInfluxDB
TimestreamQuery
TimestreamWrite
TelcoNetworkBuilder
TranscribeService
Transfer
Translate
TrustedAdvisorPublicAPI
VerifiedPermissions
VoiceID
VPCLattice
WAF
WAFRegional
WAFV2
WellArchitected
ConnectWisdomService
WorkDocs
WorkMail
WorkMailMessageFlow
WorkSpaces
WorkSpacesThinClient
WorkSpacesWeb
XRay
Core References
Customization References
Rekognition / Client / detect_faces

detect_faces
Rekognition.Client.detect_faces(**kwargs)
Detects faces within an image that is provided as input.

DetectFaces detects the 100 largest faces in the image. For each face detected, the operation returns face details. These details include a bounding box of the face, a confidence value (that the bounding box contains a face), and a fixed set of attributes such as facial landmarks (for example, coordinates of eye and mouth), pose, presence of facial occlusion, and so on.

The face-detection algorithm is most effective on frontal faces. For non-frontal or obscured faces, the algorithm might not detect the faces or might detect faces with lower confidence.

You pass the input image either as base64-encoded image bytes or as a reference to an image in an Amazon S3 bucket. If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes is not supported. The image must be either a PNG or JPEG formatted file.

Note
This is a stateless API operation. That is, the operation does not persist any data.

This operation requires permissions to perform the rekognition:DetectFaces action.

See also: AWS API Documentation

Request Syntax
response = client.detect_faces(
    Image={
        'Bytes': b'bytes',
        'S3Object': {
            'Bucket': 'string',
            'Name': 'string',
            'Version': 'string'
        }
    },
    Attributes=[
        'DEFAULT'|'ALL'|'AGE_RANGE'|'BEARD'|'EMOTIONS'|'EYE_DIRECTION'|'EYEGLASSES'|'EYES_OPEN'|'GENDER'|'MOUTH_OPEN'|'MUSTACHE'|'FACE_OCCLUDED'|'SMILE'|'SUNGLASSES',
    ]
)
Parameters:
Image (dict) –

[REQUIRED]

The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported.

If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the Bytes field. For more information, see Images in the Amazon Rekognition developer guide.

Bytes (bytes) –

Blob of image bytes up to 5 MBs. Note that the maximum image size you can pass to DetectCustomLabels is 4MB.

S3Object (dict) –

Identifies an S3 object as the image source.

Bucket (string) –

Name of the S3 bucket.

Name (string) –

S3 object key name.

Version (string) –

If the bucket is versioning enabled, you can specify the object version.

Attributes (list) –

An array of facial attributes you want to be returned. A DEFAULT subset of facial attributes - BoundingBox, Confidence, Pose, Quality, and Landmarks - will always be returned. You can request for specific facial attributes (in addition to the default list) - by using [ "DEFAULT", "FACE_OCCLUDED"] or just [ "FACE_OCCLUDED"]. You can request for all facial attributes by using [ "ALL"]. Requesting more attributes may increase response time.

If you provide both, ["ALL", "DEFAULT"], the service uses a logical “AND” operator to determine which attributes to return (in this case, all attributes).

Note that while the FaceOccluded and EyeDirection attributes are supported when using DetectFaces, they aren’t supported when analyzing videos with StartFaceDetection and GetFaceDetection.

(string) –

Return type:
dict

Returns:
Response Syntax
{
    'FaceDetails': [
        {
            'BoundingBox': {
                'Width': ...,
                'Height': ...,
                'Left': ...,
                'Top': ...
            },
            'AgeRange': {
                'Low': 123,
                'High': 123
            },
            'Smile': {
                'Value': True|False,
                'Confidence': ...
            },
            'Eyeglasses': {
                'Value': True|False,
                'Confidence': ...
            },
            'Sunglasses': {
                'Value': True|False,
                'Confidence': ...
            },
            'Gender': {
                'Value': 'Male'|'Female',
                'Confidence': ...
            },
            'Beard': {
                'Value': True|False,
                'Confidence': ...
            },
            'Mustache': {
                'Value': True|False,
                'Confidence': ...
            },
            'EyesOpen': {
                'Value': True|False,
                'Confidence': ...
            },
            'MouthOpen': {
                'Value': True|False,
                'Confidence': ...
            },
            'Emotions': [
                {
                    'Type': 'HAPPY'|'SAD'|'ANGRY'|'CONFUSED'|'DISGUSTED'|'SURPRISED'|'CALM'|'UNKNOWN'|'FEAR',
                    'Confidence': ...
                },
            ],
            'Landmarks': [
                {
                    'Type': 'eyeLeft'|'eyeRight'|'nose'|'mouthLeft'|'mouthRight'|'leftEyeBrowLeft'|'leftEyeBrowRight'|'leftEyeBrowUp'|'rightEyeBrowLeft'|'rightEyeBrowRight'|'rightEyeBrowUp'|'leftEyeLeft'|'leftEyeRight'|'leftEyeUp'|'leftEyeDown'|'rightEyeLeft'|'rightEyeRight'|'rightEyeUp'|'rightEyeDown'|'noseLeft'|'noseRight'|'mouthUp'|'mouthDown'|'leftPupil'|'rightPupil'|'upperJawlineLeft'|'midJawlineLeft'|'chinBottom'|'midJawlineRight'|'upperJawlineRight',
                    'X': ...,
                    'Y': ...
                },
            ],
            'Pose': {
                'Roll': ...,
                'Yaw': ...,
                'Pitch': ...
            },
            'Quality': {
                'Brightness': ...,
                'Sharpness': ...
            },
            'Confidence': ...,
            'FaceOccluded': {
                'Value': True|False,
                'Confidence': ...
            },
            'EyeDirection': {
                'Yaw': ...,
                'Pitch': ...,
                'Confidence': ...
            }
        },
    ],
    'OrientationCorrection': 'ROTATE_0'|'ROTATE_90'|'ROTATE_180'|'ROTATE_270'
}
Response Structure
(dict) –

FaceDetails (list) –

Details of each face found in the image.

(dict) –

Structure containing attributes of the face that the algorithm detected.

A FaceDetail object contains either the default facial attributes or all facial attributes. The default attributes are BoundingBox, Confidence, Landmarks, Pose, and Quality.

GetFaceDetection is the only Amazon Rekognition Video stored video operation that can return a FaceDetail object with all attributes. To specify which attributes to return, use the FaceAttributes input parameter for StartFaceDetection. The following Amazon Rekognition Video operations return only the default attributes. The corresponding Start operations don’t have a FaceAttributes input parameter:

GetCelebrityRecognition

GetPersonTracking

GetFaceSearch

The Amazon Rekognition Image DetectFaces and IndexFaces operations can return all facial attributes. To specify which attributes to return, use the Attributes input parameter for DetectFaces. For IndexFaces, use the DetectAttributes input parameter.

BoundingBox (dict) –

Bounding box of the face. Default attribute.

Width (float) –

Width of the bounding box as a ratio of the overall image width.

Height (float) –

Height of the bounding box as a ratio of the overall image height.

Left (float) –

Left coordinate of the bounding box as a ratio of overall image width.

Top (float) –

Top coordinate of the bounding box as a ratio of overall image height.

AgeRange (dict) –

The estimated age range, in years, for the face. Low represents the lowest estimated age and High represents the highest estimated age.

Low (integer) –

The lowest estimated age.

High (integer) –

The highest estimated age.

Smile (dict) –

Indicates whether or not the face is smiling, and the confidence level in the determination.

Value (boolean) –

Boolean value that indicates whether the face is smiling or not.

Confidence (float) –

Level of confidence in the determination.

Eyeglasses (dict) –

Indicates whether or not the face is wearing eye glasses, and the confidence level in the determination.

Value (boolean) –

Boolean value that indicates whether the face is wearing eye glasses or not.

Confidence (float) –

Level of confidence in the determination.

Sunglasses (dict) –

Indicates whether or not the face is wearing sunglasses, and the confidence level in the determination.

Value (boolean) –

Boolean value that indicates whether the face is wearing sunglasses or not.

Confidence (float) –

Level of confidence in the determination.

Gender (dict) –

The predicted gender of a detected face.

Value (string) –

The predicted gender of the face.

Confidence (float) –

Level of confidence in the prediction.

Beard (dict) –

Indicates whether or not the face has a beard, and the confidence level in the determination.

Value (boolean) –

Boolean value that indicates whether the face has beard or not.

Confidence (float) –

Level of confidence in the determination.

Mustache (dict) –

Indicates whether or not the face has a mustache, and the confidence level in the determination.

Value (boolean) –

Boolean value that indicates whether the face has mustache or not.

Confidence (float) –

Level of confidence in the determination.

EyesOpen (dict) –

Indicates whether or not the eyes on the face are open, and the confidence level in the determination.

Value (boolean) –

Boolean value that indicates whether the eyes on the face are open.

Confidence (float) –

Level of confidence in the determination.

MouthOpen (dict) –

Indicates whether or not the mouth on the face is open, and the confidence level in the determination.

Value (boolean) –

Boolean value that indicates whether the mouth on the face is open or not.

Confidence (float) –

Level of confidence in the determination.

Emotions (list) –

The emotions that appear to be expressed on the face, and the confidence level in the determination. The API is only making a determination of the physical appearance of a person’s face. It is not a determination of the person’s internal emotional state and should not be used in such a way. For example, a person pretending to have a sad face might not be sad emotionally.

(dict) –

The emotions that appear to be expressed on the face, and the confidence level in the determination. The API is only making a determination of the physical appearance of a person’s face. It is not a determination of the person’s internal emotional state and should not be used in such a way. For example, a person pretending to have a sad face might not be sad emotionally.

Type (string) –

Type of emotion detected.

Confidence (float) –

Level of confidence in the determination.

Landmarks (list) –

Indicates the location of landmarks on the face. Default attribute.

(dict) –

Indicates the location of the landmark on the face.

Type (string) –

Type of landmark.

X (float) –

The x-coordinate of the landmark expressed as a ratio of the width of the image. The x-coordinate is measured from the left-side of the image. For example, if the image is 700 pixels wide and the x-coordinate of the landmark is at 350 pixels, this value is 0.5.

Y (float) –

The y-coordinate of the landmark expressed as a ratio of the height of the image. The y-coordinate is measured from the top of the image. For example, if the image height is 200 pixels and the y-coordinate of the landmark is at 50 pixels, this value is 0.25.

Pose (dict) –

Indicates the pose of the face as determined by its pitch, roll, and yaw. Default attribute.

Roll (float) –

Value representing the face rotation on the roll axis.

Yaw (float) –

Value representing the face rotation on the yaw axis.

Pitch (float) –

Value representing the face rotation on the pitch axis.

Quality (dict) –

Identifies image brightness and sharpness. Default attribute.

Brightness (float) –

Value representing brightness of the face. The service returns a value between 0 and 100 (inclusive). A higher value indicates a brighter face image.

Sharpness (float) –

Value representing sharpness of the face. The service returns a value between 0 and 100 (inclusive). A higher value indicates a sharper face image.

Confidence (float) –

Confidence level that the bounding box contains a face (and not a different object such as a tree). Default attribute.

FaceOccluded (dict) –

FaceOccluded should return “true” with a high confidence score if a detected face’s eyes, nose, and mouth are partially captured or if they are covered by masks, dark sunglasses, cell phones, hands, or other objects. FaceOccluded should return “false” with a high confidence score if common occurrences that do not impact face verification are detected, such as eye glasses, lightly tinted sunglasses, strands of hair, and others.

Value (boolean) –

True if a detected face’s eyes, nose, and mouth are partially captured or if they are covered by masks, dark sunglasses, cell phones, hands, or other objects. False if common occurrences that do not impact face verification are detected, such as eye glasses, lightly tinted sunglasses, strands of hair, and others.

Confidence (float) –

The confidence that the service has detected the presence of a face occlusion.

EyeDirection (dict) –

Indicates the direction the eyes are gazing in, as defined by pitch and yaw.

Yaw (float) –

Value representing eye direction on the yaw axis.

Pitch (float) –

Value representing eye direction on the pitch axis.

Confidence (float) –

The confidence that the service has in its predicted eye direction.

OrientationCorrection (string) –

The value of OrientationCorrection is always null.

If the input image is in .jpeg format, it might contain exchangeable image file format (Exif) metadata that includes the image’s orientation. Amazon Rekognition uses this orientation information to perform image correction. The bounding box coordinates are translated to represent object locations after the orientation information in the Exif metadata is used to correct the image orientation. Images in .png format don’t contain Exif metadata.

Amazon Rekognition doesn’t perform image correction for images in .png format and .jpeg images without orientation information in the image Exif metadata. The bounding box coordinates aren’t translated and represent the object locations before the image is rotated.

Exceptions
Rekognition.Client.exceptions.InvalidS3ObjectException

Rekognition.Client.exceptions.InvalidParameterException

Rekognition.Client.exceptions.ImageTooLargeException

Rekognition.Client.exceptions.AccessDeniedException

Rekognition.Client.exceptions.InternalServerError

Rekognition.Client.exceptions.ThrottlingException

Rekognition.Client.exceptions.ProvisionedThroughputExceededException

Rekognition.Client.exceptions.InvalidImageFormatException

Examples
This operation detects faces in an image stored in an AWS S3 bucket.

response = client.detect_faces(
    Image={
        'S3Object': {
            'Bucket': 'mybucket',
            'Name': 'myphoto',
        },
    },
)

print(response)
Expected Output:

{
    'FaceDetails': [
        {
            'BoundingBox': {
                'Height': 0.18000000715255737,
                'Left': 0.5555555820465088,
                'Top': 0.33666667342185974,
                'Width': 0.23999999463558197,
            },
            'Confidence': 100,
            'Landmarks': [
                {
                    'Type': 'eyeLeft',
                    'X': 0.6394737362861633,
                    'Y': 0.40819624066352844,
                },
                {
                    'Type': 'eyeRight',
                    'X': 0.7266660928726196,
                    'Y': 0.41039225459098816,
                },
                {
                    'Type': 'eyeRight',
                    'X': 0.6912462115287781,
                    'Y': 0.44240960478782654,
                },
                {
                    'Type': 'mouthDown',
                    'X': 0.6306198239326477,
                    'Y': 0.46700039505958557,
                },
                {
                    'Type': 'mouthUp',
                    'X': 0.7215608954429626,
                    'Y': 0.47114261984825134,
                },
            ],
            'Pose': {
                'Pitch': 4.050806522369385,
                'Roll': 0.9950747489929199,
                'Yaw': 13.693790435791016,
            },
            'Quality': {
                'Brightness': 37.60169982910156,
                'Sharpness': 80,
            },
        },
    ],
    'OrientationCorrection': 'ROTATE_0',
    'ResponseMetadata': {
        '...': '...',
    },
}




COMPARE FACES
Hide navigation sidebarHide table of contents sidebar
Boto3 1.35.77 documentation
Toggle Light / Dark / Auto color theme
Toggle site navigation sidebar
Light Logo
Boto3 1.35.77 documentation
Search
Feedback

Do you have a suggestion to improve this website or boto3? Give us feedback.

Quickstart
A Sample Tutorial
Code Examples
Developer Guide
Security
Available Services
AccessAnalyzer
Account
ACM
ACMPCA
PrometheusService
Amplify
AmplifyBackend
AmplifyUIBuilder
APIGateway
ApiGatewayManagementApi
ApiGatewayV2
AppConfig
AppConfigData
AppFabric
Appflow
AppIntegrationsService
ApplicationAutoScaling
ApplicationInsights
CloudWatchApplicationSignals
ApplicationCostProfiler
AppMesh
AppRunner
AppStream
AppSync
MainframeModernizationApplicationTesting
ARCZonalShift
Artifact
Athena
AuditManager
AutoScaling
AutoScalingPlans
B2BI
Backup
BackupGateway
Batch
BillingandCostManagementDataExports
BillingandCostManagementPricingCalculator
Bedrock
AgentsforBedrock
AgentsforBedrockRuntime
DataAutomationforBedrock
RuntimeforBedrockDataAutomation
BedrockRuntime
Billing
BillingConductor
Braket
Budgets
CostExplorer
Chatbot
Chime
ChimeSDKIdentity
ChimeSDKMediaPipelines
ChimeSDKMeetings
ChimeSDKMessaging
ChimeSDKVoice
CleanRoomsService
CleanRoomsML
Cloud9
CloudControlApi
CloudDirectory
CloudFormation
CloudFront
CloudFrontKeyValueStore
CloudHSM
CloudHSMV2
CloudSearch
CloudSearchDomain
CloudTrail
CloudTrailDataService
CloudWatch
CodeArtifact
CodeBuild
CodeCatalyst
CodeCommit
CodeConnections
CodeDeploy
CodeGuruReviewer
CodeGuruSecurity
CodeGuruProfiler
CodePipeline
CodeStarconnections
CodeStarNotifications
CognitoIdentity
CognitoIdentityProvider
CognitoSync
Comprehend
ComprehendMedical
ComputeOptimizer
ConfigService
Connect
ConnectContactLens
ConnectCampaignService
ConnectCampaignServiceV2
ConnectCases
ConnectParticipant
ControlCatalog
ControlTower
CostOptimizationHub
CostandUsageReportService
CustomerProfiles
GlueDataBrew
DataExchange
DataPipeline
DataSync
DataZone
DAX
DeadlineCloud
Detective
DeviceFarm
DevOpsGuru
DirectConnect
ApplicationDiscoveryService
DLM
DatabaseMigrationService
DocDB
DocDBElastic
drs
DirectoryService
DirectoryServiceData
AuroraDSQL
DynamoDB
DynamoDBStreams
EBS
EC2
EC2InstanceConnect
ECR
ECRPublic
ECS
EFS
EKS
EKSAuth
ElasticInference
ElastiCache
ElasticBeanstalk
ElasticTranscoder
ElasticLoadBalancing
ElasticLoadBalancingv2
EMR
EMRContainers
EMRServerless
EntityResolution
ElasticsearchService
EventBridge
CloudWatchEvidently
finspace
FinSpaceData
Firehose
FIS
FMS
ForecastService
ForecastQueryService
FraudDetector
FreeTier
FSx
GameLift
LocationServiceMapsV2
LocationServicePlacesV2
LocationServiceRoutesV2
Glacier
GlobalAccelerator
Glue
ManagedGrafana
Greengrass
GreengrassV2
GroundStation
GuardDuty
Health
HealthLake
IAM
IdentityStore
imagebuilder
ImportExport
Inspector
inspectorscan
Inspector2
CloudWatchInternetMonitor
Invoicing
IoT
IoTDataPlane
IoTJobsDataPlane
IoT1ClickDevicesService
IoT1ClickProjects
IoTAnalytics
IoTDeviceAdvisor
IoTEvents
IoTEventsData
IoTFleetHub
IoTFleetWise
IoTSecureTunneling
IoTSiteWise
IoTThingsGraph
IoTTwinMaker
IoTWireless
IVS
ivsrealtime
ivschat
Kafka
KafkaConnect
kendra
KendraRanking
Keyspaces
Kinesis
KinesisVideoArchivedMedia
KinesisVideoMedia
KinesisVideoSignalingChannels
KinesisVideoWebRTCStorage
KinesisAnalytics
KinesisAnalyticsV2
KinesisVideo
KMS
LakeFormation
Lambda
LaunchWizard
LexModelBuildingService
LexRuntimeService
LexModelsV2
LexRuntimeV2
LicenseManager
LicenseManagerLinuxSubscriptions
LicenseManagerUserSubscriptions
Lightsail
LocationService
CloudWatchLogs
LookoutEquipment
LookoutMetrics
LookoutforVision
MainframeModernization
MachineLearning
Macie2
MailManager
ManagedBlockchain
ManagedBlockchainQuery
AgreementService
MarketplaceCatalog
MarketplaceDeploymentService
MarketplaceEntitlementService
MarketplaceReportingService
MarketplaceCommerceAnalytics
MediaConnect
MediaConvert
MediaLive
MediaPackage
MediaPackageVod
mediapackagev2
MediaStore
MediaStoreData
MediaTailor
HealthImaging
MemoryDB
MarketplaceMetering
MigrationHub
mgn
MigrationHubRefactorSpaces
MigrationHubConfig
MigrationHubOrchestrator
MigrationHubStrategyRecommendations
MQ
MTurk
MWAA
Neptune
NeptuneGraph
NeptuneData
NetworkFirewall
NetworkFlowMonitor
NetworkManager
CloudWatchNetworkMonitor
UserNotifications
UserNotificationsContacts
CloudWatchObservabilityAccessManager
CloudWatchObservabilityAdminService
Omics
OpenSearchService
OpenSearchServiceServerless
OpsWorks
OpsWorksCM
Organizations
OpenSearchIngestion
Outposts
Panorama
PartnerCentralSellingAPI
PaymentCryptographyControlPlane
PaymentCryptographyDataPlane
PcaConnectorAd
PrivateCAConnectorforSCEP
ParallelComputingService
Personalize
PersonalizeEvents
PersonalizeRuntime
PI
Pinpoint
PinpointEmail
PinpointSMSVoice
PinpointSMSVoiceV2
EventBridgePipes
Polly
Pricing
Private5G
Proton
QApps
QBusiness
QConnect
QLDB
QLDBSession
QuickSight
RAM
RecycleBin
RDS
RDSDataService
Redshift
RedshiftDataAPIService
RedshiftServerless
Rekognition
rePostPrivate
ResilienceHub
ResourceExplorer
ResourceGroups
ResourceGroupsTaggingAPI
RoboMaker
IAMRolesAnywhere
Route53
Route53RecoveryCluster
Route53RecoveryControlConfig
Route53RecoveryReadiness
Route53Domains
Route53Profiles
Route53Resolver
CloudWatchRUM
S3
S3Control
S3Outposts
S3Tables
SageMaker
AugmentedAIRuntime
SagemakerEdgeManager
SageMakerFeatureStoreRuntime
SageMakergeospatialcapabilities
SageMakerMetrics
SageMakerRuntime
SavingsPlans
EventBridgeScheduler
Schemas
SimpleDB
SecretsManager
SecurityIncidentResponse
SecurityHub
SecurityLake
ServerlessApplicationRepository
ServiceQuotas
ServiceCatalog
AppRegistry
ServiceDiscovery
SES
SESV2
Shield
signer
SimSpaceWeaver
SMS
SnowDeviceManagement
Snowball
SNS
EndUserMessagingSocial
SQS
SSM
SSMContacts
SSMIncidents
SystemsManagerQuickSetup
SsmSap
SSO
SSOAdmin
SSOOIDC
SFN
StorageGateway
STS
SupplyChain
Support
SupportApp
SWF
Synthetics
TaxSettings
Textract
TimestreamInfluxDB
TimestreamQuery
TimestreamWrite
TelcoNetworkBuilder
TranscribeService
Transfer
Translate
TrustedAdvisorPublicAPI
VerifiedPermissions
VoiceID
VPCLattice
WAF
WAFRegional
WAFV2
WellArchitected
ConnectWisdomService
WorkDocs
WorkMail
WorkMailMessageFlow
WorkSpaces
WorkSpacesThinClient
WorkSpacesWeb
XRay
Core References
Customization References
Rekognition / Client / compare_faces

compare_faces
Rekognition.Client.compare_faces(**kwargs)
Compares a face in the source input image with each of the 100 largest faces detected in the target input image.

If the source image contains multiple faces, the service detects the largest face and compares it with each face detected in the target image.

Note
CompareFaces uses machine learning algorithms, which are probabilistic. A false negative is an incorrect prediction that a face in the target image has a low similarity confidence score when compared to the face in the source image. To reduce the probability of false negatives, we recommend that you compare the target image against multiple source images. If you plan to use CompareFaces to make a decision that impacts an individual’s rights, privacy, or access to services, we recommend that you pass the result to a human for review and further validation before taking action.

You pass the input and target images either as base64-encoded image bytes or as references to images in an Amazon S3 bucket. If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes isn’t supported. The image must be formatted as a PNG or JPEG file.

In response, the operation returns an array of face matches ordered by similarity score in descending order. For each face match, the response provides a bounding box of the face, facial landmarks, pose details (pitch, roll, and yaw), quality (brightness and sharpness), and confidence value (indicating the level of confidence that the bounding box contains a face). The response also provides a similarity score, which indicates how closely the faces match.

Note
By default, only faces with a similarity score of greater than or equal to 80% are returned in the response. You can change this value by specifying the SimilarityThreshold parameter.

CompareFaces also returns an array of faces that don’t match the source image. For each face, it returns a bounding box, confidence value, landmarks, pose details, and quality. The response also returns information about the face in the source image, including the bounding box of the face and confidence value.

The QualityFilter input parameter allows you to filter out detected faces that don’t meet a required quality bar. The quality bar is based on a variety of common use cases. Use QualityFilter to set the quality bar by specifying LOW, MEDIUM, or HIGH. If you do not want to filter detected faces, specify NONE. The default value is NONE.

If the image doesn’t contain Exif metadata, CompareFaces returns orientation information for the source and target images. Use these values to display the images with the correct image orientation.

If no faces are detected in the source or target images, CompareFaces returns an InvalidParameterException error.

Note
This is a stateless API operation. That is, data returned by this operation doesn’t persist.

For an example, see Comparing Faces in Images in the Amazon Rekognition Developer Guide.

This operation requires permissions to perform the rekognition:CompareFaces action.

See also: AWS API Documentation

Request Syntax
response = client.compare_faces(
    SourceImage={
        'Bytes': b'bytes',
        'S3Object': {
            'Bucket': 'string',
            'Name': 'string',
            'Version': 'string'
        }
    },
    TargetImage={
        'Bytes': b'bytes',
        'S3Object': {
            'Bucket': 'string',
            'Name': 'string',
            'Version': 'string'
        }
    },
    SimilarityThreshold=...,
    QualityFilter='NONE'|'AUTO'|'LOW'|'MEDIUM'|'HIGH'
)
Parameters:
SourceImage (dict) –

[REQUIRED]

The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported.

If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the Bytes field. For more information, see Images in the Amazon Rekognition developer guide.

Bytes (bytes) –

Blob of image bytes up to 5 MBs. Note that the maximum image size you can pass to DetectCustomLabels is 4MB.

S3Object (dict) –

Identifies an S3 object as the image source.

Bucket (string) –

Name of the S3 bucket.

Name (string) –

S3 object key name.

Version (string) –

If the bucket is versioning enabled, you can specify the object version.

TargetImage (dict) –

[REQUIRED]

The target image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported.

If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the Bytes field. For more information, see Images in the Amazon Rekognition developer guide.

Bytes (bytes) –

Blob of image bytes up to 5 MBs. Note that the maximum image size you can pass to DetectCustomLabels is 4MB.

S3Object (dict) –

Identifies an S3 object as the image source.

Bucket (string) –

Name of the S3 bucket.

Name (string) –

S3 object key name.

Version (string) –

If the bucket is versioning enabled, you can specify the object version.

SimilarityThreshold (float) – The minimum level of confidence in the face matches that a match must meet to be included in the FaceMatches array.

QualityFilter (string) –

A filter that specifies a quality bar for how much filtering is done to identify faces. Filtered faces aren’t compared. If you specify AUTO, Amazon Rekognition chooses the quality bar. If you specify LOW, MEDIUM, or HIGH, filtering removes all faces that don’t meet the chosen quality bar. The quality bar is based on a variety of common use cases. Low-quality detections can occur for a number of reasons. Some examples are an object that’s misidentified as a face, a face that’s too blurry, or a face with a pose that’s too extreme to use. If you specify NONE, no filtering is performed. The default value is NONE.

To use quality filtering, the collection you are using must be associated with version 3 of the face model or higher.

Return type:
dict

Returns:
Response Syntax
{
    'SourceImageFace': {
        'BoundingBox': {
            'Width': ...,
            'Height': ...,
            'Left': ...,
            'Top': ...
        },
        'Confidence': ...
    },
    'FaceMatches': [
        {
            'Similarity': ...,
            'Face': {
                'BoundingBox': {
                    'Width': ...,
                    'Height': ...,
                    'Left': ...,
                    'Top': ...
                },
                'Confidence': ...,
                'Landmarks': [
                    {
                        'Type': 'eyeLeft'|'eyeRight'|'nose'|'mouthLeft'|'mouthRight'|'leftEyeBrowLeft'|'leftEyeBrowRight'|'leftEyeBrowUp'|'rightEyeBrowLeft'|'rightEyeBrowRight'|'rightEyeBrowUp'|'leftEyeLeft'|'leftEyeRight'|'leftEyeUp'|'leftEyeDown'|'rightEyeLeft'|'rightEyeRight'|'rightEyeUp'|'rightEyeDown'|'noseLeft'|'noseRight'|'mouthUp'|'mouthDown'|'leftPupil'|'rightPupil'|'upperJawlineLeft'|'midJawlineLeft'|'chinBottom'|'midJawlineRight'|'upperJawlineRight',
                        'X': ...,
                        'Y': ...
                    },
                ],
                'Pose': {
                    'Roll': ...,
                    'Yaw': ...,
                    'Pitch': ...
                },
                'Quality': {
                    'Brightness': ...,
                    'Sharpness': ...
                },
                'Emotions': [
                    {
                        'Type': 'HAPPY'|'SAD'|'ANGRY'|'CONFUSED'|'DISGUSTED'|'SURPRISED'|'CALM'|'UNKNOWN'|'FEAR',
                        'Confidence': ...
                    },
                ],
                'Smile': {
                    'Value': True|False,
                    'Confidence': ...
                }
            }
        },
    ],
    'UnmatchedFaces': [
        {
            'BoundingBox': {
                'Width': ...,
                'Height': ...,
                'Left': ...,
                'Top': ...
            },
            'Confidence': ...,
            'Landmarks': [
                {
                    'Type': 'eyeLeft'|'eyeRight'|'nose'|'mouthLeft'|'mouthRight'|'leftEyeBrowLeft'|'leftEyeBrowRight'|'leftEyeBrowUp'|'rightEyeBrowLeft'|'rightEyeBrowRight'|'rightEyeBrowUp'|'leftEyeLeft'|'leftEyeRight'|'leftEyeUp'|'leftEyeDown'|'rightEyeLeft'|'rightEyeRight'|'rightEyeUp'|'rightEyeDown'|'noseLeft'|'noseRight'|'mouthUp'|'mouthDown'|'leftPupil'|'rightPupil'|'upperJawlineLeft'|'midJawlineLeft'|'chinBottom'|'midJawlineRight'|'upperJawlineRight',
                    'X': ...,
                    'Y': ...
                },
            ],
            'Pose': {
                'Roll': ...,
                'Yaw': ...,
                'Pitch': ...
            },
            'Quality': {
                'Brightness': ...,
                'Sharpness': ...
            },
            'Emotions': [
                {
                    'Type': 'HAPPY'|'SAD'|'ANGRY'|'CONFUSED'|'DISGUSTED'|'SURPRISED'|'CALM'|'UNKNOWN'|'FEAR',
                    'Confidence': ...
                },
            ],
            'Smile': {
                'Value': True|False,
                'Confidence': ...
            }
        },
    ],
    'SourceImageOrientationCorrection': 'ROTATE_0'|'ROTATE_90'|'ROTATE_180'|'ROTATE_270',
    'TargetImageOrientationCorrection': 'ROTATE_0'|'ROTATE_90'|'ROTATE_180'|'ROTATE_270'
}
Response Structure
(dict) –

SourceImageFace (dict) –

The face in the source image that was used for comparison.

BoundingBox (dict) –

Bounding box of the face.

Width (float) –

Width of the bounding box as a ratio of the overall image width.

Height (float) –

Height of the bounding box as a ratio of the overall image height.

Left (float) –

Left coordinate of the bounding box as a ratio of overall image width.

Top (float) –

Top coordinate of the bounding box as a ratio of overall image height.

Confidence (float) –

Confidence level that the selected bounding box contains a face.

FaceMatches (list) –

An array of faces in the target image that match the source image face. Each CompareFacesMatch object provides the bounding box, the confidence level that the bounding box contains a face, and the similarity score for the face in the bounding box and the face in the source image.

(dict) –

Provides information about a face in a target image that matches the source image face analyzed by CompareFaces. The Face property contains the bounding box of the face in the target image. The Similarity property is the confidence that the source image face matches the face in the bounding box.

Similarity (float) –

Level of confidence that the faces match.

Face (dict) –

Provides face metadata (bounding box and confidence that the bounding box actually contains a face).

BoundingBox (dict) –

Bounding box of the face.

Width (float) –

Width of the bounding box as a ratio of the overall image width.

Height (float) –

Height of the bounding box as a ratio of the overall image height.

Left (float) –

Left coordinate of the bounding box as a ratio of overall image width.

Top (float) –

Top coordinate of the bounding box as a ratio of overall image height.

Confidence (float) –

Level of confidence that what the bounding box contains is a face.

Landmarks (list) –

An array of facial landmarks.

(dict) –

Indicates the location of the landmark on the face.

Type (string) –

Type of landmark.

X (float) –

The x-coordinate of the landmark expressed as a ratio of the width of the image. The x-coordinate is measured from the left-side of the image. For example, if the image is 700 pixels wide and the x-coordinate of the landmark is at 350 pixels, this value is 0.5.

Y (float) –

The y-coordinate of the landmark expressed as a ratio of the height of the image. The y-coordinate is measured from the top of the image. For example, if the image height is 200 pixels and the y-coordinate of the landmark is at 50 pixels, this value is 0.25.

Pose (dict) –

Indicates the pose of the face as determined by its pitch, roll, and yaw.

Roll (float) –

Value representing the face rotation on the roll axis.

Yaw (float) –

Value representing the face rotation on the yaw axis.

Pitch (float) –

Value representing the face rotation on the pitch axis.

Quality (dict) –

Identifies face image brightness and sharpness.

Brightness (float) –

Value representing brightness of the face. The service returns a value between 0 and 100 (inclusive). A higher value indicates a brighter face image.

Sharpness (float) –

Value representing sharpness of the face. The service returns a value between 0 and 100 (inclusive). A higher value indicates a sharper face image.

Emotions (list) –

The emotions that appear to be expressed on the face, and the confidence level in the determination. Valid values include “Happy”, “Sad”, “Angry”, “Confused”, “Disgusted”, “Surprised”, “Calm”, “Unknown”, and “Fear”.

(dict) –

The emotions that appear to be expressed on the face, and the confidence level in the determination. The API is only making a determination of the physical appearance of a person’s face. It is not a determination of the person’s internal emotional state and should not be used in such a way. For example, a person pretending to have a sad face might not be sad emotionally.

Type (string) –

Type of emotion detected.

Confidence (float) –

Level of confidence in the determination.

Smile (dict) –

Indicates whether or not the face is smiling, and the confidence level in the determination.

Value (boolean) –

Boolean value that indicates whether the face is smiling or not.

Confidence (float) –

Level of confidence in the determination.

UnmatchedFaces (list) –

An array of faces in the target image that did not match the source image face.

(dict) –

Provides face metadata for target image faces that are analyzed by CompareFaces and RecognizeCelebrities.

BoundingBox (dict) –

Bounding box of the face.

Width (float) –

Width of the bounding box as a ratio of the overall image width.

Height (float) –

Height of the bounding box as a ratio of the overall image height.

Left (float) –

Left coordinate of the bounding box as a ratio of overall image width.

Top (float) –

Top coordinate of the bounding box as a ratio of overall image height.

Confidence (float) –

Level of confidence that what the bounding box contains is a face.

Landmarks (list) –

An array of facial landmarks.

(dict) –

Indicates the location of the landmark on the face.

Type (string) –

Type of landmark.

X (float) –

The x-coordinate of the landmark expressed as a ratio of the width of the image. The x-coordinate is measured from the left-side of the image. For example, if the image is 700 pixels wide and the x-coordinate of the landmark is at 350 pixels, this value is 0.5.

Y (float) –

The y-coordinate of the landmark expressed as a ratio of the height of the image. The y-coordinate is measured from the top of the image. For example, if the image height is 200 pixels and the y-coordinate of the landmark is at 50 pixels, this value is 0.25.

Pose (dict) –

Indicates the pose of the face as determined by its pitch, roll, and yaw.

Roll (float) –

Value representing the face rotation on the roll axis.

Yaw (float) –

Value representing the face rotation on the yaw axis.

Pitch (float) –

Value representing the face rotation on the pitch axis.

Quality (dict) –

Identifies face image brightness and sharpness.

Brightness (float) –

Value representing brightness of the face. The service returns a value between 0 and 100 (inclusive). A higher value indicates a brighter face image.

Sharpness (float) –

Value representing sharpness of the face. The service returns a value between 0 and 100 (inclusive). A higher value indicates a sharper face image.

Emotions (list) –

The emotions that appear to be expressed on the face, and the confidence level in the determination. Valid values include “Happy”, “Sad”, “Angry”, “Confused”, “Disgusted”, “Surprised”, “Calm”, “Unknown”, and “Fear”.

(dict) –

The emotions that appear to be expressed on the face, and the confidence level in the determination. The API is only making a determination of the physical appearance of a person’s face. It is not a determination of the person’s internal emotional state and should not be used in such a way. For example, a person pretending to have a sad face might not be sad emotionally.

Type (string) –

Type of emotion detected.

Confidence (float) –

Level of confidence in the determination.

Smile (dict) –

Indicates whether or not the face is smiling, and the confidence level in the determination.

Value (boolean) –

Boolean value that indicates whether the face is smiling or not.

Confidence (float) –

Level of confidence in the determination.

SourceImageOrientationCorrection (string) –

The value of SourceImageOrientationCorrection is always null.

If the input image is in .jpeg format, it might contain exchangeable image file format (Exif) metadata that includes the image’s orientation. Amazon Rekognition uses this orientation information to perform image correction. The bounding box coordinates are translated to represent object locations after the orientation information in the Exif metadata is used to correct the image orientation. Images in .png format don’t contain Exif metadata.

Amazon Rekognition doesn’t perform image correction for images in .png format and .jpeg images without orientation information in the image Exif metadata. The bounding box coordinates aren’t translated and represent the object locations before the image is rotated.

TargetImageOrientationCorrection (string) –

The value of TargetImageOrientationCorrection is always null.

If the input image is in .jpeg format, it might contain exchangeable image file format (Exif) metadata that includes the image’s orientation. Amazon Rekognition uses this orientation information to perform image correction. The bounding box coordinates are translated to represent object locations after the orientation information in the Exif metadata is used to correct the image orientation. Images in .png format don’t contain Exif metadata.

Amazon Rekognition doesn’t perform image correction for images in .png format and .jpeg images without orientation information in the image Exif metadata. The bounding box coordinates aren’t translated and represent the object locations before the image is rotated.

Exceptions
Rekognition.Client.exceptions.InvalidParameterException

Rekognition.Client.exceptions.InvalidS3ObjectException

Rekognition.Client.exceptions.ImageTooLargeException

Rekognition.Client.exceptions.AccessDeniedException

Rekognition.Client.exceptions.InternalServerError

Rekognition.Client.exceptions.ThrottlingException

Rekognition.Client.exceptions.ProvisionedThroughputExceededException

Rekognition.Client.exceptions.InvalidImageFormatException

Examples
This operation compares the largest face detected in the source image with each face detected in the target image.

response = client.compare_faces(
    SimilarityThreshold=90,
    SourceImage={
        'S3Object': {
            'Bucket': 'mybucket',
            'Name': 'mysourceimage',
        },
    },
    TargetImage={
        'S3Object': {
            'Bucket': 'mybucket',
            'Name': 'mytargetimage',
        },
    },
)

print(response)
Expected Output:

{
    'FaceMatches': [
        {
            'Face': {
                'BoundingBox': {
                    'Height': 0.33481481671333313,
                    'Left': 0.31888890266418457,
                    'Top': 0.4933333396911621,
                    'Width': 0.25,
                },
                'Confidence': 99.9991226196289,
            },
            'Similarity': 100,
        },
    ],
    'SourceImageFace': {
        'BoundingBox': {
            'Height': 0.33481481671333313,
            'Left': 0.31888890266418457,
            'Top': 0.4933333396911621,
            'Width': 0.25,
        },
        'Confidence': 99.9991226196289,
    },
    'ResponseMetadata': {
        '...': '...',
    },
}



